{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Job Market and Salaries Analysis \n",
    "\n",
    "For our final project, we have selected the Stack Overflow Developer Survey dataset, \n",
    "which contains detailed responses from developers regarding their job roles, skills, \n",
    "technologies used, and salary information. This dataset is particularly relevant to the \n",
    "tech industry, which is a major focus of our group, and will provide insights into the tech \n",
    "job market by collecting responses from developers worldwide. It covers various topics \n",
    "such as job roles, salary, coding activities, education, technology usage, and job \n",
    "satisfaction.<br>\n",
    "\n",
    "Team Eyy<br>\n",
    "Members:  \n",
    "- Julianne Kristine D. Aban \n",
    "- Derich Andre G. Arcilla \n",
    "- Jennifer Bendoy \n",
    "- Richelle Ann C. Candidato \n",
    "- Marc Francis B. Gomolon \n",
    "- Phoebe Kae A. Plasus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA SET & LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('survey_results_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING CODE OF EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Years of Experience YearsCode(overall coding experience) && YearsCodePro (coding experience as a professional)\n",
    "\n",
    "# Step 1: Replace 'NA' strings with NaN\n",
    "df.replace('NA', pd.NA, inplace=True)\n",
    "\n",
    "# Step 2: Convert 'YearsCode' and 'YearsCodePro' columns to numeric, \n",
    "# forcing errors to NaN for any other non-numeric values\n",
    "df['YearsCode'] = pd.to_numeric(df['YearsCode'], errors='coerce')\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Step 3: Impute missing values with the mean of each column\n",
    "df['YearsCode'] = df['YearsCode'].fillna(df['YearsCode'].mean())\n",
    "df['YearsCodePro'] = df['YearsCodePro'].fillna(df['YearsCodePro'].mean())\n",
    "\n",
    "# Round the results to whole numbers (integers)\n",
    "df['YearsCode'] = df['YearsCode'].round().astype(int)\n",
    "df['YearsCodePro'] = df['YearsCodePro'].round().astype(int)\n",
    "\n",
    "# Print the cleaned DataFrame with the two columns\n",
    "# print(df[['YearsCode', 'YearsCodePro']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING EDUCATION LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the EdLevel column:\n",
    "# - Remove text in parentheses (e.g., \"(e.g. American high school, etc.)\")\n",
    "# - Strip any extra spaces\n",
    "df['EdLevel'] = df['EdLevel'].apply(lambda x: re.sub(r'\\(.*\\)', '', str(x)).strip())\n",
    "\n",
    "# Mapping dictionary for converting text to numeric values\n",
    "edlevel_mapping = {\n",
    "    'Primary/elementary school': 1,\n",
    "    'Secondary school': 2,\n",
    "    \"Bachelor's degree\": 3,\n",
    "    'Associate degree': 4,\n",
    "    \"Master's degree\": 5,\n",
    "    'Professional degree': 6,\n",
    "    'Some college/university study without earning a degree': 0,\n",
    "    'Something else': 0\n",
    "}\n",
    "\n",
    "# Replace text with numeric values according to the mapping\n",
    "df['EdLevel'] = df['EdLevel'].replace(edlevel_mapping)\n",
    "\n",
    "# Convert the column to numeric values (in case there are still mixed types)\n",
    "df['EdLevel'] = pd.to_numeric(df['EdLevel'], errors='coerce')\n",
    "\n",
    "# Handle missing values (NaN) and replace with -1\n",
    "df['EdLevel'] = df['EdLevel'].fillna(-1)\n",
    "\n",
    "# Print only the cleaned 'EdLevel' column\n",
    "# print(df['EdLevel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING ORGSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the column name\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean the 'OrgSize' column: strip spaces, convert to lowercase, and remove commas\n",
    "df['OrgSize'] = df['OrgSize'].str.strip()  # Remove leading/trailing spaces\n",
    "df['OrgSize'] = df['OrgSize'].str.lower()  # Convert to lowercase\n",
    "df['OrgSize'] = df['OrgSize'].str.replace(',', '')  # Remove commas\n",
    "df['OrgSize'] = df['OrgSize'].str.replace('to', '-')  # Standardize \"to\" as \"-\"\n",
    "df['OrgSize'] = df['OrgSize'].str.replace(' ', '')  # Remove extra spaces\n",
    "\n",
    "# Handle NaN values (if you want to replace them with a specific value like 'na')\n",
    "df['OrgSize'] = df['OrgSize'].fillna('na')  # Replace NaN with 'na' or any other value you prefer\n",
    "\n",
    "# Mapping the categories directly to numeric values\n",
    "orgsize_map = {\n",
    "    'freelancer': 1,                # Freelancer becomes 1\n",
    "    '2-99employees': 2,             # Standardize \"2 - 99 employees\" to \"2-99employees\"\n",
    "    '100-999employees': 3,          # Standardize \"100 - 999 employees\" to \"100-999employees\"\n",
    "    '1000-4999employees': 4,        # Standardize \"1000 to 4999 employees\" to \"1000-4999employees\"\n",
    "    '5000ormoreemployees': 5,       # Standardize \"5000 or more employees\" to \"5000ormoreemployees\"\n",
    "    'i don\\'t know': -1,            # \"I don't know\" becomes -1\n",
    "    'na': -1                        # \"NA\" becomes -1\n",
    "}\n",
    "\n",
    "# Replace text categories with numeric values directly in the 'OrgSize' column\n",
    "df['OrgSize'] = df['OrgSize'].replace(orgsize_map)\n",
    "\n",
    "# Print the cleaned 'OrgSize' column\n",
    "# print(df['OrgSize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING LANGUAGE HAVE WORKED WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values by filling them with an empty string or dropping rows with NaN values\n",
    "df['LanguageHaveWorkedWith'] = df['LanguageHaveWorkedWith'].fillna('')\n",
    "\n",
    "# Split the 'LanguageHaveWorkedWith' column by semicolon\n",
    "df['Technologies'] = df['LanguageHaveWorkedWith'].str.split(';')\n",
    "\n",
    "# Standardize technology names (strip extra spaces, title case)\n",
    "df['Technologies'] = df['Technologies'].apply(lambda x: [tech.strip().title() for tech in x if tech])\n",
    "\n",
    "# Flatten the list of technologies and create a set of unique technologies\n",
    "all_technologies = set([tech for sublist in df['Technologies'] for tech in sublist])\n",
    "\n",
    "# One-hot encode by creating a column for each technology\n",
    "for tech in all_technologies:\n",
    "    df[tech] = df['Technologies'].apply(lambda x: 1 if tech in x else 0)\n",
    "\n",
    "# Drop the original 'LanguageHaveWorkedWith' and 'Technologies' columns\n",
    "df.drop(columns=['LanguageHaveWorkedWith', 'Technologies'], inplace=True)\n",
    "\n",
    "# Print the one-hot encoded results\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DATABASE HAVE WORKED WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values by filling them with an empty string or dropping rows with NaN values\n",
    "df['DatabaseHaveWorkedWith'] = df['DatabaseHaveWorkedWith'].fillna('')\n",
    "\n",
    "# Function to clean and one-hot encode a column\n",
    "def clean_and_encode(column_name):\n",
    "    # Split the column by semicolon\n",
    "    df[column_name + '_Technologies'] = df[column_name].str.split(';')\n",
    "    \n",
    "    # Standardize technology names (strip extra spaces, title case)\n",
    "    df[column_name + '_Technologies'] = df[column_name + '_Technologies'].apply(lambda x: [tech.strip().title() for tech in x if tech])\n",
    "    \n",
    "    # Flatten the list of technologies and create a set of unique technologies\n",
    "    all_technologies = set([tech for sublist in df[column_name + '_Technologies'] for tech in sublist])\n",
    "    \n",
    "    # One-hot encode by creating a column for each technology\n",
    "    for tech in all_technologies:\n",
    "        df[tech] = df[column_name + '_Technologies'].apply(lambda x: 1 if tech in x else 0)\n",
    "    \n",
    "    # Drop the original technology columns\n",
    "    df.drop(columns=[column_name, column_name + '_Technologies'], inplace=True)\n",
    "\n",
    "# Clean and one-hot encode the 'DatabaseHaveWorkedWith' column\n",
    "clean_and_encode('DatabaseHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING JOB SATISFACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"NA\" with NaN (missing values)\n",
    "df['JobSat'] = df['JobSat'].replace('NA', np.nan)\n",
    "\n",
    "# Convert the column to numeric values (in case some values are strings or other types)\n",
    "df['JobSat'] = pd.to_numeric(df['JobSat'], errors='coerce')\n",
    "\n",
    "# Impute missing values with the median (you can change to mean if preferred)\n",
    "df['JobSat'] = df['JobSat'].fillna(df['JobSat'].median())  # or df['JobSat'].mean()\n",
    "\n",
    "# Optional: If there are any outliers or invalid values (e.g., negative values), you can handle them\n",
    "# For instance, we could cap the values to a valid range, such as 1-10 for job satisfaction scores\n",
    "# df['JobSat'] = df['JobSat'].clip(lower=1, upper=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DEVTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DevType  DevTypeNumeric\n",
      "0            NaN            -1.0\n",
      "1      Developer             2.0\n",
      "2      Developer             2.0\n",
      "3      Developer             2.0\n",
      "4      Developer             2.0\n",
      "...          ...             ...\n",
      "65432  Developer             2.0\n",
      "65433        NaN            -1.0\n",
      "65434  Developer             2.0\n",
      "65435        NaN            -1.0\n",
      "65436        NaN            -1.0\n",
      "\n",
      "[65437 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace \"NA\" with NaN (missing values) in DevType column\n",
    "df['DevType'] = df['DevType'].replace('NA', np.nan)\n",
    "\n",
    "# Define a mapping to group similar roles\n",
    "dev_type_mapping = {\n",
    "    'Academic researcher': 'Researcher',\n",
    "    'Blockchain': 'Developer',\n",
    "    'Cloud infrastructure engineer': 'Engineer',\n",
    "    'Data engineer': 'Data Professional',\n",
    "    'Data or business analyst': 'Data Professional',\n",
    "    'Data scientist or machine learning specialist': 'Data Professional',\n",
    "    'Database administrator': 'Data Professional',\n",
    "    'Designer': 'Designer',\n",
    "    'Developer Advocate': 'Developer',\n",
    "    'Developer Experience': 'Developer',\n",
    "    'Developer, AI': 'Developer',\n",
    "    'Developer back-end': 'Developer',\n",
    "    'Developer, desktop or enterprise applications': 'Developer',\n",
    "    'Developer, embedded applications': 'Developer',\n",
    "    'Developer, front-end': 'Developer',\n",
    "    'Developer, full-stack': 'Developer',\n",
    "    'Developer, game or graphics': 'Developer',\n",
    "    'Developer, mobile': 'Developer',\n",
    "    'Developer, QA or test': 'Developer',\n",
    "    'DevOps specialist': 'Engineer',\n",
    "    'Educator': 'Educator',\n",
    "    'Engineer site reliability': 'Engineer',\n",
    "    'Engineering manager': 'Manager',\n",
    "    'Hardware manager': 'Manager',\n",
    "    'Marketing or sales professional': 'Business',\n",
    "    'Others': 'Other',\n",
    "    'Product manager': 'Manager',\n",
    "    'Project manager': 'Manager',\n",
    "    'Research and Development role': 'Researcher',\n",
    "    'Scientist': 'Researcher',\n",
    "    'Security professional': 'Security',\n",
    "    'Senior Executive (C-Suite, VP)': 'Executive',\n",
    "    'Student': 'Student',\n",
    "    'System administrator': 'Engineer'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['DevType'] = df['DevType'].map(dev_type_mapping)\n",
    "\n",
    "# Convert categorical column to numeric using a mapping for the grouped roles\n",
    "dev_type_numeric_mapping = {\n",
    "    'Researcher': 1,\n",
    "    'Developer': 2,\n",
    "    'Engineer': 3,\n",
    "    'Data Professional': 4,\n",
    "    'Designer': 5,\n",
    "    'Manager': 6,\n",
    "    'Business': 7,\n",
    "    'Other': 8,\n",
    "    'Educator': 9,\n",
    "    'Security': 10,\n",
    "    'Executive': 11,\n",
    "    'Student': 12\n",
    "}\n",
    "\n",
    "# Apply the numeric mapping to the 'DevType' column\n",
    "df['DevTypeNumeric'] = df['DevType'].map(dev_type_numeric_mapping)\n",
    "\n",
    "# Fill NaN values (optional, depending on your analysis)\n",
    "df['DevTypeNumeric'] = df['DevTypeNumeric'].fillna(-1)  # Use -1 or another placeholder for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cleaned File\n",
    "\n",
    "output_file_path = \"cleaned_file.csv\"\n",
    "\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Analysis Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori Algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
