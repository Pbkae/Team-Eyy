{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Job Market and Salaries Analysis \n",
    "\n",
    "For our final project, we have selected the Stack Overflow Developer Survey dataset, \n",
    "which contains detailed responses from developers regarding their job roles, skills, \n",
    "technologies used, and salary information. This dataset is particularly relevant to the \n",
    "tech industry, which is a major focus of our group, and will provide insights into the tech \n",
    "job market by collecting responses from developers worldwide. It covers various topics \n",
    "such as job roles, salary, coding activities, education, technology usage, and job \n",
    "satisfaction.<br>\n",
    "\n",
    "Team Eyy<br>\n",
    "Members:  \n",
    "- Julianne Kristine D. Aban \n",
    "- Derich Andre G. Arcilla \n",
    "- Jennifer Bendoy \n",
    "- Richelle Ann C. Candidato \n",
    "- Marc Francis B. Gomolon \n",
    "- Phoebe Kae A. Plasus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA SET & LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv('survey_results_filtered.csv')\n",
    "df = pd.read_csv('survey_results_public.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand display settings to show all columns\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 200)     # Adjust rows if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Column Name  Missing Values Data Type\n",
      "0                        ResponseId               0     int64\n",
      "1                        MainBranch               0    object\n",
      "2                               Age               0    object\n",
      "3                        Employment               0    object\n",
      "4                        RemoteWork           10631    object\n",
      "5                             Check               0    object\n",
      "6                  CodingActivities           10971    object\n",
      "7                           EdLevel            4653    object\n",
      "8                         LearnCode            4949    object\n",
      "9                   LearnCodeOnline           16200    object\n",
      "10                          TechDoc           24540    object\n",
      "11                        YearsCode            5568    object\n",
      "12                     YearsCodePro           13827    object\n",
      "13                          DevType            5992    object\n",
      "14                          OrgSize           17957    object\n",
      "15                PurchaseInfluence           18031    object\n",
      "16                       BuyNewTool           20256    object\n",
      "17                       BuildvsBuy           22079    object\n",
      "18                      TechEndorse           21769    object\n",
      "19                          Country            6507    object\n",
      "20                         Currency           18753    object\n",
      "21                        CompTotal           31697   float64\n",
      "22           LanguageHaveWorkedWith            5692    object\n",
      "23           LanguageWantToWorkWith            9685    object\n",
      "24                  LanguageAdmired           14565    object\n",
      "25           DatabaseHaveWorkedWith           15183    object\n",
      "26           DatabaseWantToWorkWith           22879    object\n",
      "27                  DatabaseAdmired           26880    object\n",
      "28           PlatformHaveWorkedWith           23071    object\n",
      "29           PlatformWantToWorkWith           30905    object\n",
      "30                  PlatformAdmired           34060    object\n",
      "31           WebframeHaveWorkedWith           20276    object\n",
      "32           WebframeWantToWorkWith           26902    object\n",
      "33                  WebframeAdmired           30494    object\n",
      "34           EmbeddedHaveWorkedWith           43223    object\n",
      "35           EmbeddedWantToWorkWith           47837    object\n",
      "36                  EmbeddedAdmired           48704    object\n",
      "37           MiscTechHaveWorkedWith           25994    object\n",
      "38           MiscTechWantToWorkWith           32473    object\n",
      "39                  MiscTechAdmired           35841    object\n",
      "40          ToolsTechHaveWorkedWith           12955    object\n",
      "41          ToolsTechWantToWorkWith           19353    object\n",
      "42                 ToolsTechAdmired           21440    object\n",
      "43     NEWCollabToolsHaveWorkedWith            7845    object\n",
      "44     NEWCollabToolsWantToWorkWith           13350    object\n",
      "45            NEWCollabToolsAdmired           14726    object\n",
      "46                OpSysPersonal use            7263    object\n",
      "47            OpSysProfessional use           12464    object\n",
      "48   OfficeStackAsyncHaveWorkedWith           17344    object\n",
      "49   OfficeStackAsyncWantToWorkWith           26471    object\n",
      "50          OfficeStackAsyncAdmired           28233    object\n",
      "51    OfficeStackSyncHaveWorkedWith            9892    object\n",
      "52    OfficeStackSyncWantToWorkWith           18726    object\n",
      "53           OfficeStackSyncAdmired           20725    object\n",
      "54        AISearchDevHaveWorkedWith           20984    object\n",
      "55        AISearchDevWantToWorkWith           28736    object\n",
      "56               AISearchDevAdmired           29894    object\n",
      "57                       NEWSOSites            5151    object\n",
      "58                      SOVisitFreq            5901    object\n",
      "59                        SOAccount            5877    object\n",
      "60                       SOPartFreq           20200    object\n",
      "61                            SOHow            6475    object\n",
      "62                           SOComm            6274    object\n",
      "63                         AISelect            4530    object\n",
      "64                           AISent           19564    object\n",
      "65                            AIBen           28543    object\n",
      "66                            AIAcc           28135    object\n",
      "67                        AIComplex           28416    object\n",
      "68            AIToolCurrently Using           30365    object\n",
      "69        AIToolInterested in Using           34746    object\n",
      "70    AIToolNot interested in Using           41023    object\n",
      "71       AINextMuch more integrated           51999    object\n",
      "72                  AINextNo change           52939    object\n",
      "73            AINextMore integrated           41009    object\n",
      "74            AINextLess integrated           63082    object\n",
      "75       AINextMuch less integrated           64289    object\n",
      "76                         AIThreat           20748    object\n",
      "77                         AIEthics           23889    object\n",
      "78                     AIChallenges           27906    object\n",
      "79                          TBranch           20960    object\n",
      "80                           ICorPM           35636    object\n",
      "81                          WorkExp           35779   float64\n",
      "82                      Knowledge_1           36773    object\n",
      "83                      Knowledge_2           37416    object\n",
      "84                      Knowledge_3           37342    object\n",
      "85                      Knowledge_4           37407    object\n",
      "86                      Knowledge_5           37557    object\n",
      "87                      Knowledge_6           37573    object\n",
      "88                      Knowledge_7           37659    object\n",
      "89                      Knowledge_8           37679    object\n",
      "90                      Knowledge_9           37802    object\n",
      "91                      Frequency_1           37068    object\n",
      "92                      Frequency_2           37073    object\n",
      "93                      Frequency_3           37727    object\n",
      "94                    TimeSearching           36526    object\n",
      "95                    TimeAnswering           36593    object\n",
      "96                      Frustration           37186    object\n",
      "97                 ProfessionalTech           37673    object\n",
      "98                ProfessionalCloud           36946    object\n",
      "99             ProfessionalQuestion           36630    object\n",
      "100                        Industry           36579    object\n",
      "101                  JobSatPoints_1           36113   float64\n",
      "102                  JobSatPoints_4           36044   float64\n",
      "103                  JobSatPoints_5           36026   float64\n",
      "104                  JobSatPoints_6           35987   float64\n",
      "105                  JobSatPoints_7           35989   float64\n",
      "106                  JobSatPoints_8           35981   float64\n",
      "107                  JobSatPoints_9           35981   float64\n",
      "108                 JobSatPoints_10           35987   float64\n",
      "109                 JobSatPoints_11           35992   float64\n",
      "110                    SurveyLength            9255    object\n",
      "111                      SurveyEase            9199    object\n",
      "112             ConvertedCompYearly           42002   float64\n",
      "113                          JobSat           36311   float64\n"
     ]
    }
   ],
   "source": [
    "# Display column information: name, number of missing values, and dtype\n",
    "column_info = pd.DataFrame({\n",
    "    'Column Name': df.columns,\n",
    "    'Missing Values': df.isnull().sum(),\n",
    "    'Data Type': df.dtypes\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Print the column information\n",
    "print(column_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 50% missing values:\n",
      "PlatformAdmired                  52.050063\n",
      "EmbeddedHaveWorkedWith           66.052845\n",
      "EmbeddedWantToWorkWith           73.103901\n",
      "EmbeddedAdmired                  74.428840\n",
      "MiscTechAdmired                  54.771765\n",
      "AIToolInterested in Using        53.098400\n",
      "AIToolNot interested in Using    62.690832\n",
      "AINextMuch more integrated       79.464217\n",
      "AINextNo change                  80.900714\n",
      "AINextMore integrated            62.669438\n",
      "AINextLess integrated            96.401119\n",
      "AINextMuch less integrated       98.245641\n",
      "ICorPM                           54.458487\n",
      "WorkExp                          54.677018\n",
      "Knowledge_1                      56.196036\n",
      "Knowledge_2                      57.178660\n",
      "Knowledge_3                      57.065575\n",
      "Knowledge_4                      57.164907\n",
      "Knowledge_5                      57.394135\n",
      "Knowledge_6                      57.418586\n",
      "Knowledge_7                      57.550010\n",
      "Knowledge_8                      57.580574\n",
      "Knowledge_9                      57.768541\n",
      "Frequency_1                      56.646851\n",
      "Frequency_2                      56.654492\n",
      "Frequency_3                      57.653927\n",
      "TimeSearching                    55.818574\n",
      "TimeAnswering                    55.920962\n",
      "Frustration                      56.827177\n",
      "ProfessionalTech                 57.571405\n",
      "ProfessionalCloud                56.460412\n",
      "ProfessionalQuestion             55.977505\n",
      "Industry                         55.899568\n",
      "JobSatPoints_1                   55.187432\n",
      "JobSatPoints_4                   55.081987\n",
      "JobSatPoints_5                   55.054480\n",
      "JobSatPoints_6                   54.994881\n",
      "JobSatPoints_7                   54.997937\n",
      "JobSatPoints_8                   54.985711\n",
      "JobSatPoints_9                   54.985711\n",
      "JobSatPoints_10                  54.994881\n",
      "JobSatPoints_11                  55.002522\n",
      "ConvertedCompYearly              64.186928\n",
      "JobSat                           55.490013\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Filter columns with more than 50% missing values\n",
    "high_missing_cols = missing_percentage[missing_percentage > 50]\n",
    "print(\"Columns with more than 50% missing values:\")\n",
    "print(high_missing_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping columns: (65437, 70)\n",
      "Remaining columns (70):\n",
      "Index(['ResponseId', 'MainBranch', 'Age', 'Employment', 'RemoteWork', 'Check',\n",
      "       'CodingActivities', 'EdLevel', 'LearnCode', 'LearnCodeOnline',\n",
      "       'TechDoc', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize',\n",
      "       'PurchaseInfluence', 'BuyNewTool', 'BuildvsBuy', 'TechEndorse',\n",
      "       'Country', 'Currency', 'CompTotal', 'LanguageHaveWorkedWith',\n",
      "       'LanguageWantToWorkWith', 'LanguageAdmired', 'DatabaseHaveWorkedWith',\n",
      "       'DatabaseWantToWorkWith', 'DatabaseAdmired', 'PlatformHaveWorkedWith',\n",
      "       'PlatformWantToWorkWith', 'WebframeHaveWorkedWith',\n",
      "       'WebframeWantToWorkWith', 'WebframeAdmired', 'MiscTechHaveWorkedWith',\n",
      "       'MiscTechWantToWorkWith', 'ToolsTechHaveWorkedWith',\n",
      "       'ToolsTechWantToWorkWith', 'ToolsTechAdmired',\n",
      "       'NEWCollabToolsHaveWorkedWith', 'NEWCollabToolsWantToWorkWith',\n",
      "       'NEWCollabToolsAdmired', 'OpSysPersonal use', 'OpSysProfessional use',\n",
      "       'OfficeStackAsyncHaveWorkedWith', 'OfficeStackAsyncWantToWorkWith',\n",
      "       'OfficeStackAsyncAdmired', 'OfficeStackSyncHaveWorkedWith',\n",
      "       'OfficeStackSyncWantToWorkWith', 'OfficeStackSyncAdmired',\n",
      "       'AISearchDevHaveWorkedWith', 'AISearchDevWantToWorkWith',\n",
      "       'AISearchDevAdmired', 'NEWSOSites', 'SOVisitFreq', 'SOAccount',\n",
      "       'SOPartFreq', 'SOHow', 'SOComm', 'AISelect', 'AISent', 'AIBen', 'AIAcc',\n",
      "       'AIComplex', 'AIToolCurrently Using', 'AIThreat', 'AIEthics',\n",
      "       'AIChallenges', 'TBranch', 'SurveyLength', 'SurveyEase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "df_cleaned = df.drop(columns=high_missing_cols.index)\n",
    "print(f\"Dataset shape after dropping columns: {df_cleaned.shape}\")\n",
    "\n",
    "# Show the names of the remaining columns\n",
    "remaining_columns = df_cleaned.columns\n",
    "print(f\"Remaining columns ({len(remaining_columns)}):\")\n",
    "print(remaining_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in numerical columns:\n",
      "ResponseId    0\n",
      "CompTotal     0\n",
      "dtype: int64\n",
      "Missing values in categorical columns:\n",
      "MainBranch                        0\n",
      "Age                               0\n",
      "Employment                        0\n",
      "RemoteWork                        0\n",
      "Check                             0\n",
      "CodingActivities                  0\n",
      "EdLevel                           0\n",
      "LearnCode                         0\n",
      "LearnCodeOnline                   0\n",
      "TechDoc                           0\n",
      "YearsCode                         0\n",
      "YearsCodePro                      0\n",
      "DevType                           0\n",
      "OrgSize                           0\n",
      "PurchaseInfluence                 0\n",
      "BuyNewTool                        0\n",
      "BuildvsBuy                        0\n",
      "TechEndorse                       0\n",
      "Country                           0\n",
      "Currency                          0\n",
      "LanguageHaveWorkedWith            0\n",
      "LanguageWantToWorkWith            0\n",
      "LanguageAdmired                   0\n",
      "DatabaseHaveWorkedWith            0\n",
      "DatabaseWantToWorkWith            0\n",
      "DatabaseAdmired                   0\n",
      "PlatformHaveWorkedWith            0\n",
      "PlatformWantToWorkWith            0\n",
      "WebframeHaveWorkedWith            0\n",
      "WebframeWantToWorkWith            0\n",
      "WebframeAdmired                   0\n",
      "MiscTechHaveWorkedWith            0\n",
      "MiscTechWantToWorkWith            0\n",
      "ToolsTechHaveWorkedWith           0\n",
      "ToolsTechWantToWorkWith           0\n",
      "ToolsTechAdmired                  0\n",
      "NEWCollabToolsHaveWorkedWith      0\n",
      "NEWCollabToolsWantToWorkWith      0\n",
      "NEWCollabToolsAdmired             0\n",
      "OpSysPersonal use                 0\n",
      "OpSysProfessional use             0\n",
      "OfficeStackAsyncHaveWorkedWith    0\n",
      "OfficeStackAsyncWantToWorkWith    0\n",
      "OfficeStackAsyncAdmired           0\n",
      "OfficeStackSyncHaveWorkedWith     0\n",
      "OfficeStackSyncWantToWorkWith     0\n",
      "OfficeStackSyncAdmired            0\n",
      "AISearchDevHaveWorkedWith         0\n",
      "AISearchDevWantToWorkWith         0\n",
      "AISearchDevAdmired                0\n",
      "NEWSOSites                        0\n",
      "SOVisitFreq                       0\n",
      "SOAccount                         0\n",
      "SOPartFreq                        0\n",
      "SOHow                             0\n",
      "SOComm                            0\n",
      "AISelect                          0\n",
      "AISent                            0\n",
      "AIBen                             0\n",
      "AIAcc                             0\n",
      "AIComplex                         0\n",
      "AIToolCurrently Using             0\n",
      "AIThreat                          0\n",
      "AIEthics                          0\n",
      "AIChallenges                      0\n",
      "TBranch                           0\n",
      "SurveyLength                      0\n",
      "SurveyEase                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing numerical values with median\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_cleaned[numerical_cols] = df_cleaned[numerical_cols].fillna(df_cleaned[numerical_cols].median())\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "df_cleaned[categorical_cols] = df_cleaned[categorical_cols].fillna(df_cleaned[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Check for missing values in numerical columns\n",
    "print(\"Missing values in numerical columns:\")\n",
    "print(df_cleaned[numerical_cols].isnull().sum())\n",
    "\n",
    "# Check for missing values in categorical columns\n",
    "print(\"Missing values in categorical columns:\")\n",
    "print(df_cleaned[categorical_cols].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cleaned File\n",
    "df_cleaned.to_csv('cleaned_survey_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('cleaned_survey_results.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING CODE OF EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning Years of Experience YearsCode(overall coding experience) && YearsCodePro (coding experience as a professional)\n",
    "\n",
    "# # Step 1: Replace 'NA' strings with NaN\n",
    "# df.replace('NA', pd.NA, inplace=True)\n",
    "\n",
    "# # Step 2: Convert 'YearsCode' and 'YearsCodePro' columns to numeric, \n",
    "# # forcing errors to NaN for any other non-numeric values\n",
    "# df['YearsCode'] = pd.to_numeric(df['YearsCode'], errors='coerce')\n",
    "# df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# # Step 3: Impute missing values with the mean of each column\n",
    "# df['YearsCode'] = df['YearsCode'].fillna(df['YearsCode'].mean())\n",
    "# df['YearsCodePro'] = df['YearsCodePro'].fillna(df['YearsCodePro'].mean())\n",
    "\n",
    "# # Round the results to whole numbers (integers)\n",
    "# df['YearsCode'] = df['YearsCode'].round().astype(int)\n",
    "# df['YearsCodePro'] = df['YearsCodePro'].round().astype(int)\n",
    "\n",
    "# # Print the cleaned DataFrame with the two columns\n",
    "# # print(df[['YearsCode', 'YearsCodePro']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING EDUCATION LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean the EdLevel column:\n",
    "# # - Remove text in parentheses (e.g., \"(e.g. American high school, etc.)\")\n",
    "# # - Strip any extra spaces\n",
    "# df['EdLevel'] = df['EdLevel'].apply(lambda x: re.sub(r'\\(.*\\)', '', str(x)).strip())\n",
    "\n",
    "# # Mapping dictionary for converting text to numeric values\n",
    "# edlevel_mapping = {\n",
    "#     'Primary/elementary school': 1,\n",
    "#     'Secondary school': 2,\n",
    "#     \"Bachelor's degree\": 3,\n",
    "#     'Associate degree': 4,\n",
    "#     \"Master's degree\": 5,\n",
    "#     'Professional degree': 6,\n",
    "#     'Some college/university study without earning a degree': 0,\n",
    "#     'Something else': 0\n",
    "# }\n",
    "\n",
    "# # Replace text with numeric values according to the mapping\n",
    "# df['EdLevel'] = df['EdLevel'].replace(edlevel_mapping)\n",
    "\n",
    "# # Convert the column to numeric values (in case there are still mixed types)\n",
    "# df['EdLevel'] = pd.to_numeric(df['EdLevel'], errors='coerce')\n",
    "\n",
    "# # Handle missing values (NaN) and replace with -1\n",
    "# df['EdLevel'] = df['EdLevel'].fillna(-1)\n",
    "\n",
    "# # Print only the cleaned 'EdLevel' column\n",
    "# # print(df['EdLevel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING ORGSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display unique values in OrgSize and their counts\n",
    "# print(\"Unique values in OrgSize before parsing:\")\n",
    "# print(df_cluster['OrgSize'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to parse OrgSize values\n",
    "# def parse_org_size(value):\n",
    "#     if pd.isnull(value):  # Handle missing values\n",
    "#         return np.nan\n",
    "#     value = str(value).lower()\n",
    "    \n",
    "#     # Handle ranges like \"100 to 499 employees\"\n",
    "#     if \"to\" in value:\n",
    "#         try:\n",
    "#             return int(value.split(\"to\")[0].replace(\",\", \"\").strip())\n",
    "#         except ValueError:\n",
    "#             return np.nan\n",
    "    \n",
    "#     # Handle \"10,000 or more employees\"\n",
    "#     elif \"or more\" in value:\n",
    "#         try:\n",
    "#             return int(value.split(\"or\")[0].replace(\",\", \"\").strip())\n",
    "#         except ValueError:\n",
    "#             return np.nan\n",
    "\n",
    "#     # Handle freelancer entries\n",
    "#     elif \"just me\" in value or \"freelancer\" in value:\n",
    "#         return 1  # Single individual\n",
    "\n",
    "#     # Handle unknown or NA\n",
    "#     elif \"i don't know\" in value or value in [\"na\"]:\n",
    "#         return np.nan\n",
    "\n",
    "#     # Default fallback for unexpected values\n",
    "#     else:\n",
    "#         return np.nan\n",
    "\n",
    "# # Display original unique values in OrgSize\n",
    "# print(\"Unique values in OrgSize before parsing:\")\n",
    "# print(df_cluster['OrgSize'].value_counts(dropna=False))\n",
    "\n",
    "# # Apply parsing to OrgSize column\n",
    "# df_cluster['OrgSize'] = df_cluster['OrgSize'].map(parse_org_size)\n",
    "\n",
    "# # Fill missing values with the median\n",
    "# df_cluster['OrgSize'] = df_cluster['OrgSize'].fillna(df_cluster['OrgSize'].median())\n",
    "\n",
    "# # Display transformed OrgSize values after parsing\n",
    "# print(\"\\nUnique values in OrgSize after parsing:\")\n",
    "# print(df_cluster['OrgSize'].value_counts())\n",
    "\n",
    "# # Optional: Display final values after filling missing values\n",
    "# print(\"\\nUnique values in OrgSize after filling missing values:\")\n",
    "# print(df_cluster['OrgSize'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING LANGUAGE HAVE WORKED WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle NaN values by filling them with an empty string or dropping rows with NaN values\n",
    "# df['LanguageHaveWorkedWith'] = df['LanguageHaveWorkedWith'].fillna('')\n",
    "\n",
    "# # Split the 'LanguageHaveWorkedWith' column by semicolon\n",
    "# df['Technologies'] = df['LanguageHaveWorkedWith'].str.split(';')\n",
    "\n",
    "# # Standardize technology names (strip extra spaces, title case)\n",
    "# df['Technologies'] = df['Technologies'].apply(lambda x: [tech.strip().title() for tech in x if tech])\n",
    "\n",
    "# # Flatten the list of technologies and create a set of unique technologies\n",
    "# all_technologies = set([tech for sublist in df['Technologies'] for tech in sublist])\n",
    "\n",
    "# # One-hot encode by creating a column for each technology\n",
    "# for tech in all_technologies:\n",
    "#     df[tech] = df['Technologies'].apply(lambda x: 1 if tech in x else 0)\n",
    "\n",
    "# # Drop the original 'LanguageHaveWorkedWith' and 'Technologies' columns\n",
    "# df.drop(columns=['LanguageHaveWorkedWith', 'Technologies'], inplace=True)\n",
    "\n",
    "# # Print the one-hot encoded results\n",
    "# # print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DATABASE HAVE WORKED WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle NaN values by filling them with an empty string or dropping rows with NaN values\n",
    "# df['DatabaseHaveWorkedWith'] = df['DatabaseHaveWorkedWith'].fillna('')\n",
    "\n",
    "# # Function to clean and one-hot encode a column\n",
    "# def clean_and_encode(column_name):\n",
    "#     # Split the column by semicolon\n",
    "#     df[column_name + '_Technologies'] = df[column_name].str.split(';')\n",
    "    \n",
    "#     # Standardize technology names (strip extra spaces, title case)\n",
    "#     df[column_name + '_Technologies'] = df[column_name + '_Technologies'].apply(lambda x: [tech.strip().title() for tech in x if tech])\n",
    "    \n",
    "#     # Flatten the list of technologies and create a set of unique technologies\n",
    "#     all_technologies = set([tech for sublist in df[column_name + '_Technologies'] for tech in sublist])\n",
    "    \n",
    "#     # One-hot encode by creating a column for each technology\n",
    "#     for tech in all_technologies:\n",
    "#         df[tech] = df[column_name + '_Technologies'].apply(lambda x: 1 if tech in x else 0)\n",
    "    \n",
    "#     # Drop the original technology columns\n",
    "#     df.drop(columns=[column_name, column_name + '_Technologies'], inplace=True)\n",
    "\n",
    "# # Clean and one-hot encode the 'DatabaseHaveWorkedWith' column\n",
    "# clean_and_encode('DatabaseHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DEVTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace \"NA\" with NaN (missing values) in DevType column\n",
    "# df['DevType'] = df['DevType'].replace('NA', np.nan)\n",
    "\n",
    "# # Define a mapping to group similar roles\n",
    "# dev_type_mapping = {\n",
    "#     'Academic researcher': 'Researcher',\n",
    "#     'Blockchain': 'Developer',\n",
    "#     'Cloud infrastructure engineer': 'Engineer',\n",
    "#     'Data engineer': 'Data Professional',\n",
    "#     'Data or business analyst': 'Data Professional',\n",
    "#     'Data scientist or machine learning specialist': 'Data Professional',\n",
    "#     'Database administrator': 'Data Professional',\n",
    "#     'Designer': 'Designer',\n",
    "#     'Developer Advocate': 'Developer',\n",
    "#     'Developer Experience': 'Developer',\n",
    "#     'Developer, AI': 'Developer',\n",
    "#     'Developer back-end': 'Developer',\n",
    "#     'Developer, desktop or enterprise applications': 'Developer',\n",
    "#     'Developer, embedded applications': 'Developer',\n",
    "#     'Developer, front-end': 'Developer',\n",
    "#     'Developer, full-stack': 'Developer',\n",
    "#     'Developer, game or graphics': 'Developer',\n",
    "#     'Developer, mobile': 'Developer',\n",
    "#     'Developer, QA or test': 'Developer',\n",
    "#     'DevOps specialist': 'Engineer',\n",
    "#     'Educator': 'Educator',\n",
    "#     'Engineer site reliability': 'Engineer',\n",
    "#     'Engineering manager': 'Manager',\n",
    "#     'Hardware manager': 'Manager',\n",
    "#     'Marketing or sales professional': 'Business',\n",
    "#     'Others': 'Other',\n",
    "#     'Product manager': 'Manager',\n",
    "#     'Project manager': 'Manager',\n",
    "#     'Research and Development role': 'Researcher',\n",
    "#     'Scientist': 'Researcher',\n",
    "#     'Security professional': 'Security',\n",
    "#     'Senior Executive (C-Suite, VP)': 'Executive',\n",
    "#     'Student': 'Student',\n",
    "#     'System administrator': 'Engineer'\n",
    "# }\n",
    "\n",
    "# # Apply the mapping\n",
    "# df['DevType'] = df['DevType'].map(dev_type_mapping)\n",
    "\n",
    "# # Convert categorical column to numeric using a mapping for the grouped roles\n",
    "# dev_type_numeric_mapping = {\n",
    "#     'Researcher': 1,\n",
    "#     'Developer': 2,\n",
    "#     'Engineer': 3,\n",
    "#     'Data Professional': 4,\n",
    "#     'Designer': 5,\n",
    "#     'Manager': 6,\n",
    "#     'Business': 7,\n",
    "#     'Other': 8,\n",
    "#     'Educator': 9,\n",
    "#     'Security': 10,\n",
    "#     'Executive': 11,\n",
    "#     'Student': 12\n",
    "# }\n",
    "\n",
    "# # Apply the numeric mapping to the 'DevType' column\n",
    "# df['DevTypeNumeric'] = df['DevType'].map(dev_type_numeric_mapping)\n",
    "\n",
    "# # Fill NaN values (optional, depending on your analysis)\n",
    "# df['DevTypeNumeric'] = df['DevTypeNumeric'].fillna(-1)  # Use -1 or another placeholder for missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Analysis Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori Algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
